{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPr+yfaIYcHqVx2zqf54bDR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03ddPqSQST5I","executionInfo":{"status":"ok","timestamp":1742706010988,"user_tz":-300,"elapsed":24674,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"945321c7-be0b-4d0a-e06c-463da7eda8ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"z8VD_rfraOsW","executionInfo":{"status":"ok","timestamp":1742706659777,"user_tz":-300,"elapsed":173,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# **Optical Flow**\n","\n","Optical flow refers to the pattern of **apparent motion** of objects between two consecutive frames, caused by either object movement or camera movement.\n","\n","### **Key Assumptions in Optical Flow Analysis**\n","1. **Pixel Intensity Consistency**: The brightness of an object remains the same across frames.\n","2. **Neighboring Pixels Move Together**: The surrounding pixels of the tracked object move similarly.\n","\n","### **Optical Flow in OpenCV**\n","- OpenCV provides methods to track objects between frames.\n","- The user must **specify points** to track (e.g., detecting a face first, then tracking it).\n","- The **Lucas-Kanade Method** is used for **sparse optical flow**, meaning it tracks only selected points.\n","- The **Gunnar Farneback Method** is used for **dense optical flow**, which tracks motion across the entire frame.\n","\n","### **Tracking Example**\n","**Note** danish you have to insert picture here for this example.\n","- A moving ball in consecutive frames could either mean the **ball is moving** or the **camera is shifting**.\n","- Optical flow algorithms cannot differentiate between object motion and camera movement.\n","- The function in OpenCV takes:\n","  - A previous frame $( I_t )$\n","  - A set of tracking points $( p )$\n","  - The current frame $( I_{t+1} )$\n","\n","  to estimate motion.\n","\n","### **Sparse vs. Dense Optical Flow**\n","#### **1. Lucas-Kanade Method (Sparse Optical Flow)**\n","- Tracks only a few selected points.\n","- Ideal for tracking specific objects, like facial features.\n","\n","#### **2. Gunnar Farneback Method (Dense Optical Flow)**\n","- Tracks motion for **all pixels** in an image.\n","- Highlights moving objects with colors indicating direction.\n","\n","### **Mathematical Background**\n","- These methods rely on **linear algebra** and **calculus**.\n","- The Lucas-Kanade method is based on solving the following equation:\n","\n","  $$\n","  I_x u + I_y v + I_t = 0\n","  $$\n","\n","  where:\n","  - $( I_x, I_y )$ are image gradients,\n","  - $( I_t )$ is the temporal gradient,\n","  - $( (u, v) )$ represents the optical flow vector.\n","\n","- The Gunnar Farneback method uses polynomial expansion to estimate flow vectors.\n","\n","The lecture concludes with implementing both **sparse** and **dense** optical flow in OpenCV.\n"],"metadata":{"id":"QPMZVPCgYUdX"}},{"cell_type":"markdown","source":["# Optical Flow Using Lucas-Kanade Method\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Ah6O8xf-halJ"}},{"cell_type":"markdown","source":["## Detecting Feature Points\n","We start by detecting key points in the first frame using **Shi-Tomasi Corner Detection**. This helps us find strong feature points (like corners) that are easier to track across frames. These points are chosen because they have high contrast in multiple directions, making them more reliable for motion tracking"],"metadata":{"id":"b5TnP9Hbhkc0"}},{"cell_type":"code","source":["## Parameters to detect corners\n","corner_track_params = dict(maxCorners = 10,qualityLevel = 0.3,MinDistance = 7,blockSize = 7)"],"metadata":{"id":"fTjdMrDnXuHa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting Parameters for Optical Flow\n","We define key parameters that influence the tracking accuracy:\n","- **Window size**: Determines the local area used for computing optical flow.\n","- **Pyramid levels**: Enables multi-scale tracking, allowing for better handling of large motions.\n","- **Termination criteria**: Defines when the iterative optimization process should stop.\n","\n","These parameters ensure that the **Lucas-Kanade method** tracks points effectively while maintaining performance."],"metadata":{"id":"8YbcvEmzhrk6"}},{"cell_type":"code","source":["## Parameters for Lucas-kanade flow motion.\n","## Smaller window more sensitive to noise and could be missed important information(larger motion between frames).\n","## By selecting larger, we can catch that larger motion between frames.\n","\n","lk_params = dict(winSize=(200,200),maxLevel = 2,criteria = (cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_COUNT,10,0.03))"],"metadata":{"id":"HZFZB-zEaq1O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## Reading Video Frames and Preprocessing\n","We process the video frame by frame. Each frame is **converted to grayscale** because optical flow operates on intensity values rather than color. This reduces computational complexity and improves accuracy.\n","\n","## Calculating Optical Flow\n","Using OpenCV’s `calcOpticalFlowPyrLK()`, we estimate the movement of feature points from the previous frame to the current one. This function works by analyzing pixel intensity variations within the predefined window size and across pyramid levels, solving for the displacement of tracked points.\n","\n","## Filtering Tracked Points\n","Some feature points may get lost due to factors like **occlusion, motion blur, or changes in lighting conditions**. We apply filtering techniques to remove invalid points and retain only the successfully tracked ones.\n","\n","## Visualizing Motion\n","To visualize the motion, we **draw lines connecting the previous and new positions** of the tracked points. This creates a motion trail effect, allowing us to see the movement of objects in the video. The visualization helps in understanding how objects or the camera itself is moving."],"metadata":{"id":"4dlRUTGfh3gY"}},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","\n","ret, prev_frame = cap.read()\n","prev_gray = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\n","\n","## POINTS TO TRACK\n","\n","prevPts = cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params)\n","## Drawing lines on the video\n","mask = np.zeros_like(prev_frame)\n","\n","while True:\n","  ret,frame = cap.read()\n","  frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n","\n","  nextPts,status,err = cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts,None,**lk_params)\n","  good_new = nextPts[ status == 1]\n","  good_prev = prevPts[ status == 1]\n","\n","  for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n","    x_new,y_new = new.ravel()\n","    x_prev,y_prev = prev.ravel()\n","\n","    mask = cv2.line(mask,(x_new,y_new),(x_prev,y_prev),(0,255,0),3)\n","    frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n","\n","  img = cv2.add(frame,mask)\n","  cv2.imshow('tracking'.img)\n","\n","  k = cv2.waitKey(30) & 0xFF\n","  if k == 27:\n","    break\n","  prev_gray = frame_gray.copy()\n","  prevPts = good_new.reshape(-1,1,2)\n","\n","\n","cv2.destroyAllWindows()\n","cap.release()\n"],"metadata":{"id":"7R63BWE6cRjn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Dense Optical Flow in OpenCV**\n","\n","This explanation is about **Dense Optical Flow** in OpenCV, which is used to track movement across an entire image rather than just a few points, as in **Lucas-Kanade Optical Flow**.\n","\n","## **Step-by-Step Explanation**\n","\n","### **1. Capturing Video Input**\n","- The program captures a **video stream**, typically from a **USB camera**, using OpenCV.\n","- The **first frame** of the video is read and converted to **grayscale**, since optical flow works better with **single-channel images**.\n","\n","### **2. Setting Up HSV Mask**\n","- The program creates an **HSV (Hue, Saturation, Value) mask** to colorize movement **based on direction**.\n","- This helps visualize movement, where different directions will be represented in **different colors**.\n","\n","### **3. Reading Frames & Computing Optical Flow**\n","- The next frame of the video is captured and converted to **grayscale**.\n","- OpenCV’s **Farneback Optical Flow** function is used:\n","  $$\n","  \\text{cv2.calcOpticalFlowFarneback}\n","  $$\n","  - Computes dense optical flow across the **whole image**.\n","  - Uses several parameters (like **pyramid levels**, **window size**, **iterations**, etc.) to optimize flow calculation.\n","\n","### **4. Converting Flow Data**\n","- The flow data consists of **X and Y displacement vectors** for each pixel.\n","- These vectors are converted to **polar coordinates** using:\n","  $$\n","  \\text{cv2.cartToPolar(dx, dy)}\n","  $$\n","  - **Angle** $(\\theta)$ determines the **hue (color)** in the HSV mask.\n","  - **Magnitude** $(r)$ determines the **saturation (intensity of movement)**.\n","\n","### **5. Applying Color Mapping**\n","- The **angle** values are mapped to **hue (color)** values:\n","  $$\n","  H = \\frac{\\theta \\cdot 180}{\\pi \\cdot 2}\n","  $$\n","- The **magnitude** values are normalized to fit within **0-255**:\n","  $$\n","  V = \\frac{\\text{magnitude} - \\text{min}}{\\text{max} - \\text{min}} \\times 255\n","  $$\n","- The **HSV mask** is then converted back to **BGR format** for display.\n","\n","### **6. Displaying the Output**\n","The result is shown using **cv2.imshow()**, where:\n","\n","- **Objects moving to the left** → **Blue**.\n","- **Objects moving to the right** → **Red**.\n","- **Objects moving up** → **Purple**.\n","- **Objects moving down** → **Green**.\n","\n","\n","### **7. Looping & Exiting**\n","- The process continues in a **loop** until the user **presses the Escape key** (`27`).\n","- The program then **releases the video capture** and **closes all windows**.\n","\n","## **Main Takeaways**\n","- **Dense Optical Flow** analyzes movement for **all pixels**, rather than selected **feature points**.\n","- **Color mapping** helps **visualize movement directions**.\n","- OpenCV’s **Farneback method** is used for **efficient optical flow computation**.\n","- This technique is useful in:\n","  - **Motion tracking**\n","  - **Video stabilization**\n","  - **Object detection in videos**\n"],"metadata":{"id":"uXnLsHDHi4yE"}},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","\n","ret, frame1 = cap.read()\n","prevImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","\n","hsv_mask = np.zeros_like(frame1)\n","hsv_mask[:,:,1] = 255\n","\n","\n","\n","while True:\n","  ret,frame2 = cap.read()\n","  nextImg = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n","\n","  flow = cv2.calcOpticalFlowFarneback(prevImg,nextImg,None,0.5,3,15,3,5,1.2,0)\n","\n","  mag,ang = cv2.cartToPolor(flow[:,:,0],flow[:,:,1],angleInDegrees=True)\n","\n","  hsv_mask[:,:,0] = ang/2\n","  hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n","\n","  bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n","  cv2.imshow('frame',bgr)\n","\n","  k = cv2.waitKey(30) & 0xFF\n","  if k == 27:\n","    break\n","  prevImg = nextImg.copy()\n","\n","\n","cv2.destroyAllWindows()\n","cap.release()\n"],"metadata":{"id":"JeJ6nZGah5yR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sFyKUDlfmVCk"},"execution_count":null,"outputs":[]}]}